<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Cheat Sheet ML - Estilo Futurista</title>
    <link rel="stylesheet" href="style.css" />
</head>
<body>
    <div class="glowing-dots">
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
    </div>

    <header>
        <h1 class="typing-effect">Cheat Sheet - Valida√ß√£o e M√©tricas em ML</h1>
        <p class="typing-effect-subheader">Com Scikit-learn + Imbalanced-learn</p>
    </header>

    <main>
        <section>
            <h2>1. Divis√£o dos Dados</h2>
            <p>Separa√ß√£o estratificada em treino, teste e valida√ß√£o:</p>
            <code data-text="from sklearn.model_selection import train_test_split">from sklearn.model_selection import train_test_split</code>
            <code data-text="x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, stratify=y)">x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, stratify=y)</code>
            <p class="explanation-box">
                A divis√£o dos dados √© um passo crucial para garantir que seu modelo de Machine Learning seja avaliado de forma justa. `train_test_split` do Scikit-learn divide seu conjunto de dados em subconjuntos para treinamento e teste. O par√¢metro `stratify=y` √© especialmente importante em problemas de classifica√ß√£o com classes desbalanceadas, pois garante que a propor√ß√£o das classes seja mantida em cada um dos subconjuntos, evitando que um conjunto de teste tenha pouqu√≠ssimos exemplos de uma classe minorit√°ria, por exemplo. Isso permite uma avalia√ß√£o mais robusta do desempenho do modelo.
            </p>
        </section>

        <section>
            <h2>2. Cria√ß√£o de Modelos</h2>
            <code data-text="from sklearn.tree import DecisionTreeClassifier">from sklearn.tree import DecisionTreeClassifier</code>
            <code data-text="modelo = DecisionTreeClassifier(max_depth=10)">modelo = DecisionTreeClassifier(max_depth=10)</code>
            <code data-text="from sklearn.ensemble import RandomForestClassifier">from sklearn.ensemble import RandomForestClassifier</code>
            <code data-text="modelo = RandomForestClassifier(max_depth=10)">modelo = RandomForestClassifier(max_depth=10)</code>
            <p class="explanation-box">
                Aqui voc√™ define o tipo de modelo de Machine Learning que deseja utilizar. `DecisionTreeClassifier` √© um modelo fundamental que toma decis√µes baseadas em regras de √°rvore. `RandomForestClassifier` √© um modelo de ensemble que combina v√°rias √°rvores de decis√£o para melhorar a precis√£o e reduzir o overfitting. O par√¢metro `max_depth` limita a profundidade da √°rvore, ajudando a controlar a complexidade do modelo e evitar que ele se ajuste demais aos dados de treinamento.
            </p>
        </section>

        <section>
            <h2>3. Ajuste e Previs√£o</h2>
            <code data-text="modelo.fit(x_treino, y_treino)">modelo.fit(x_treino, y_treino)</code>
            <code data-text="y_previsto = modelo.predict(x_val)">y_previsto = modelo.predict(x_val)</code>
            <p class="explanation-box">
                O m√©todo `fit()` √© onde o modelo "aprende" os padr√µes dos dados de treinamento. Ele ajusta seus par√¢metros internos com base nas caracter√≠sticas (`x_treino`) e nos r√≥tulos (`y_treino`) fornecidos. Ap√≥s o treinamento, voc√™ pode usar o m√©todo `predict()` para gerar previs√µes (`y_previsto`) para novos dados de entrada (`x_val`). √â crucial que os dados usados para previs√£o (`x_val`) sejam diferentes dos dados de treinamento para avaliar a capacidade de generaliza√ß√£o do modelo.
            </p>
        </section>

        <section>
            <h2>4. Avalia√ß√£o</h2>
            <code data-text="modelo.score(x_val, y_val)">modelo.score(x_val, y_val)</code>
            <p class="explanation-box">
                O m√©todo `modelo.score()` oferece uma maneira r√°pida de obter a acur√°cia do seu modelo em um conjunto de dados de teste ou valida√ß√£o. Para problemas de classifica√ß√£o, ele retorna a propor√ß√£o de previs√µes corretas. √â uma m√©trica de alto n√≠vel que indica a performance geral, mas deve ser complementada com outras m√©tricas (como precis√£o, recall, F1-score) para uma compreens√£o mais aprofundada, especialmente em casos de desbalanceamento de classes.
            </p>
        </section>

        <section>
            <h2>5. Matriz de Confus√£o</h2>
            <code data-text="from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay">from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay</code>
            <code data-text="ConfusionMatrixDisplay.from_predictions(y_val, y_previsto)">ConfusionMatrixDisplay.from_predictions(y_val, y_previsto)</code>
            <p class="explanation-box">
                A matriz de confus√£o √© uma ferramenta essencial para visualizar o desempenho de um algoritmo de classifica√ß√£o. Ela mostra o n√∫mero de verdadeiros positivos, verdadeiros negativos, falsos positivos e falsos negativos. Isso permite que voc√™ entenda n√£o apenas quantos acertos o modelo teve, mas tamb√©m onde ele cometeu erros (confundindo uma classe com outra). √â particularmente √∫til para identificar problemas como o vi√©s em modelos que n√£o classificam bem uma classe minorit√°ria.
            </p>
        </section>

        <section>
            <h2>6. M√©tricas</h2>
            <code data-text="from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score</code>
            <code data-text="accuracy_score(y_val, y_previsto)">accuracy_score(y_val, y_previsto)</code>
            <code data-text="precision_score(y_val, y_previsto)">precision_score(y_val, y_previsto)</code>
            <code data-text="recall_score(y_val, y_previsto)">recall_score(y_val, y_previsto)</code>
            <p class="explanation-box">
                Al√©m da acur√°cia, outras m√©tricas fornecem uma vis√£o mais granular do desempenho:
                <ul>
                    <li><b>Acur√°cia:</b> (Verdadeiros Positivos + Verdadeiros Negativos) / Total. √â a propor√ß√£o de previs√µes corretas. Pode ser enganosa em classes desbalanceadas.</li>
                    <li><b>Precis√£o:</b> Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos). Responde: Dos que o modelo previu como positivo, quantos realmente eram positivos?</li>
                    <li><b>Recall (Sensibilidade):</b> Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos). Responde: Dos que eram realmente positivos, quantos o modelo identificou corretamente?</li>
                    <li><b>F1-Score:</b> M√©dia harm√¥nica de precis√£o e recall. √â √∫til quando voc√™ precisa de um equil√≠brio entre precis√£o e recall, especialmente em conjuntos de dados com classes desbalanceadas.</li>
                </ul>
            </p>
        </section>

        <section>
            <h2>7. Curvas de Avalia√ß√£o</h2>
            <code data-text="from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay">from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay</code>
            <code data-text="RocCurveDisplay.from_predictions(y_val, y_previsto)">RocCurveDisplay.from_predictions(y_val, y_previsto)</code>
            <p class="explanation-box">
                Curvas de avalia√ß√£o s√£o gr√°ficos que ajudam a entender o desempenho do modelo em diferentes limiares de classifica√ß√£o:
                <ul>
                    <li><b>Curva ROC (Receiver Operating Characteristic):</b> Plota a Taxa de Verdadeiros Positivos (Recall) contra a Taxa de Falsos Positivos. Uma curva mais pr√≥xima do canto superior esquerdo indica um modelo melhor. A √Årea Sob a Curva ROC (AUC-ROC) √© uma m√©trica comum para avaliar modelos de classifica√ß√£o bin√°ria.</li>
                    <li><b>Curva Precision-Recall:</b> Plota a Precis√£o contra o Recall. √â particularmente √∫til em conjuntos de dados desbalanceados, onde a classe positiva √© rara. Modelos com melhor desempenho ter√£o uma curva mais pr√≥xima do canto superior direito.</li>
                </ul>
            </p>
        </section>

        <section>
            <h2>8. Balanceamento</h2>
            <code data-text="from imblearn.over_sampling import SMOTE">from imblearn.over_sampling import SMOTE</code>
            <code data-text="from imblearn.under_sampling import NearMiss">from imblearn.under_sampling import NearMiss</code>
            <code data-text="SMOTE().fit_resample(x, y)">SMOTE().fit_resample(x, y)</code>
            <p class="explanation-box">
                Quando seu conjunto de dados tem um n√∫mero significativamente diferente de exemplos em cada classe (desbalanceamento), os modelos podem tender a classificar a classe majorit√°ria com mais precis√£o e ignorar a minorit√°ria. O `imbalanced-learn` oferece t√©cnicas para lidar com isso:
                <ul>
                    <li><b>SMOTE (Synthetic Minority Over-sampling Technique):</b> √â uma t√©cnica de "oversampling" que cria novos exemplos sint√©ticos para a classe minorit√°ria, interpolando entre os exemplos existentes.</li>
                    <li><b>NearMiss:</b> √â uma t√©cnica de "undersampling" que remove exemplos da classe majorit√°ria para balancear o conjunto de dados. Existem diferentes vers√µes (e.g., NearMiss-1, NearMiss-2) que usam diferentes heur√≠sticas para selecionar os exemplos a serem removidos.</li>
                </ul>
                Essas t√©cnicas ajudam a melhorar o desempenho do modelo na classe minorit√°ria.
            </p>
        </section>

        <section>
            <h2>9. Pipeline</h2>
            <code data-text="from imblearn.pipeline import Pipeline as imbpipeline">from imblearn.pipeline import Pipeline as imbpipeline</code>
            <code data-text="pipeline = imbpipeline([('oversample', SMOTE()), ('modelo', modelo)])">pipeline = imbpipeline([('oversample', SMOTE()), ('modelo', modelo)])</code>
            <p class="explanation-box">
                Usar um `Pipeline` √© uma pr√°tica recomendada no Machine Learning, especialmente quando se lida com transforma√ß√µes de dados (como balanceamento) e treinamento de modelos. O `imbpipeline` do `imbalanced-learn` estende o `Pipeline` do Scikit-learn para incluir etapas de balanceamento de dados. Isso garante que o balanceamento seja aplicado apenas aos dados de treinamento dentro de cada itera√ß√£o de valida√ß√£o cruzada, prevenindo o vazamento de dados (`data leakage`) e garantindo uma avalia√ß√£o justa do modelo.
            </p>
        </section>

        <section>
            <h2>10. Valida√ß√£o Cruzada</h2>
            <code data-text="from sklearn.model_selection import StratifiedKFold, cross_val_score">from sklearn.model_selection import StratifiedKFold, cross_val_score</code>
            <code data-text="skf = StratifiedKFold(n_splits=5, shuffle=True)">skf = StratifiedKFold(n_splits=5, shuffle=True)</code>
            <code data-text="cross_val_score(modelo, x, y, cv=skf)">cross_val_score(modelo, x, y, cv=skf)</code>
            <p class="explanation-box">
                A valida√ß√£o cruzada √© uma t√©cnica robusta para avaliar o desempenho do modelo e garantir que ele generalize bem para dados n√£o vistos. Em vez de uma √∫nica divis√£o treino/teste, o `StratifiedKFold` divide o conjunto de dados em "k" dobras (folds), mantendo a propor√ß√£o de classes em cada dobra. O modelo √© treinado "k" vezes, usando uma dobra diferente para teste a cada vez, e as m√©tricas s√£o calculadas para cada itera√ß√£o. O `cross_val_score` executa esse processo e retorna as pontua√ß√µes de cada fold, fornecendo uma estimativa mais confi√°vel do desempenho real do modelo. O `shuffle=True` randomiza os dados antes da divis√£o.
            </p>
        </section>
    </main>

    <footer>
        <p>Desenvolvido por  <a href="https://scikit-learn.org/stable/" target="_blank">Cau√£ Santos</a>. </br> Ultilizando <a href="https://scikit-learn.org/stable/" target="_blank">scikit-learn</a> e <a href="https://imbalanced-learn.org/stable/" target="_blank">imbalanced-learn</a>.</p>
    </footer>

    <button id="backToTopBtn" title="Voltar ao Topo">üîù</button>

    <script src="/script.js"></script>
</body>
</html>
